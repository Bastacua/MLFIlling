# -*- coding: utf-8 -*-
"""EDA_SHP_BASTA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dNlsqKMNk5GkX83xBmq2oG9vGabKKa7R
"""



import pandas as pd
import numpy as np
from collections import Counter

#Change and Input Dataset here
#dataset=pd.read_csv('/SHP1.csv')

dataset=pd.read_csv('/content/drive/MyDrive/KN INTERN/SHP1.csv')



#Drop undefined in dataset
dataset = dataset.drop(dataset[dataset['txtItemDesc'] == 'undefined'].index)

#Drop unecessary column
dataset=dataset.drop(columns=['bitActive','intIdParameterE1'])

dataset.info()

dataset[dataset["txtSourceNumber"]==44521]

dataset = dataset[dataset['intMachineSpeed'] >= 20]

class one_batch:
  def dataprep(self,sku):
    filtered_data = dataset.loc[dataset['txtItemDesc'] == sku]
    batch=filtered_data['txtSourceNumber'].iloc[0]
    return batch

  def print_all(self,sku):
    batch=self.dataprep(sku)
    display(dataset.loc[dataset['txtSourceNumber']== batch])

  def print_unique_in_col(self,sku):
    batch=self.dataprep(sku)
    display(dataset.loc[dataset['txtSourceNumber']==batch].nunique())

  def print_value_unique(self, sku):
        batch = self.dataprep(sku)
        filtered_data = dataset.loc[dataset['txtSourceNumber'] == batch]

        redundant = []
        constant = []

        for col in filtered_data.columns:
            unique_vals = filtered_data[col].unique()
            unique_count = filtered_data[col].nunique()

            print(f"Column: {col}")
            print(f"Unique Count: {unique_count}")
            print(f"Unique Values: {unique_vals}\n")

            if unique_count > 1:
              redundant.append((col))
            elif unique_count == 1:
              constant.append((col))

        redundant_df = pd.DataFrame(redundant, columns=['Column'])
        constant_df = pd.DataFrame(constant, columns=['Column'])

        return redundant_df,constant_df

  def print_unique_summary(self, sku):
      batch = self.dataprep(sku)
      filtered_data = dataset.loc[dataset['txtSourceNumber'] == batch]

      table_data = []

      for col in filtered_data.columns:
          unique_vals = filtered_data[col].unique()
          unique_count = filtered_data[col].nunique()

          lowest_val = filtered_data[col].min()
          highest_val = filtered_data[col].max()

          table_data.append([col, unique_count,unique_vals, lowest_val, highest_val])

      summary_table = pd.DataFrame(table_data, columns=["Parameter Name","Amount of Unique Values" ,"Unique Values", "Lowest Value", "Highest Value"])

      display(summary_table)

onebatch=one_batch()

class all_batch:

  def time_batch(self,sku):
    filtered_data = dataset.loc[dataset['txtItemDesc'] == sku]

    result = filtered_data.groupby('txtSourceNumber').agg(
      InsertedDate=('InsertedDate', 'first'),
      FirstInsertedTime=('InsertedTime', 'first'),
      LastInsertedTime=('InsertedTime', 'last')
    ).reset_index()

    display(result)

  def print_all_batch(self,sku):

    filtered_data = dataset.loc[dataset['txtItemDesc'] == sku]

    unique_sources = filtered_data['txtSourceNumber'].unique()

    summary_tables = {}

    for source in unique_sources:
      source_data = filtered_data.loc[filtered_data['txtSourceNumber'] == source]

      table_data = []
      for col in source_data.columns:
          unique_vals = source_data[col].unique()
          unique_count = source_data[col].nunique()
          lowest_val = source_data[col].min()
          highest_val = source_data[col].max()

          table_data.append([col, unique_count, unique_vals, lowest_val, highest_val])

      summary_table = pd.DataFrame(table_data, columns=["Parameter Name", "Amount of Unique Values", "Unique Values", "Lowest Value", "Highest Value"])

      summary_tables[source] = summary_table

    for source, table in summary_tables.items():
      print(f"\nSummary for txtSourceNumber: {source}\n")
      display(table)


  def unique_all_batch(self,sku):
    filtered_data = dataset.loc[dataset['txtItemDesc'] == sku]

    summary_data = []

    for col in filtered_data.columns:
      all_unique_values = set(filtered_data[col].unique())

      summary_data.append({
          "Feature Name": col,
          "Total Unique Count": len(all_unique_values),
          "All Unique Values": list(all_unique_values)
      })

    summary_table = pd.DataFrame(summary_data)

    display(summary_table)

    rel=summary_table.loc[summary_table['Total Unique Count'] >1, ['Feature Name']]
    cons=summary_table.loc[summary_table['Total Unique Count'] ==1, ['Feature Name']]

    return rel,cons

  def print_value_unique_batches(self,sku):

    filtered_data = dataset.loc[dataset['txtItemDesc'] == sku]

    unique_sources = filtered_data['txtSourceNumber'].unique()

    table_data = []

    for col in filtered_data.columns:
      col_data = [col]

      for source in unique_sources:
          source_data = filtered_data.loc[filtered_data['txtSourceNumber'] == source]

          unique_count = source_data[col].nunique()
          unique_vals = source_data[col].unique()

          col_data.extend([unique_count, unique_vals])

      table_data.append(col_data)

    columns = ["Parameter Name"]
    for source in unique_sources:
      columns.extend([
          f"Unique Count ({source})",
          f"Unique Values ({source})"
      ])

    comparison_table = pd.DataFrame(table_data, columns=columns)

    display(comparison_table)

  def print_count_value_all_batches(self,sku):


    filtered_data = dataset.loc[dataset['txtItemDesc'] == sku]

    unique_sources = filtered_data['txtSourceNumber'].unique()

    dominance_data = {} #for unique each batch
    all_dominance_data = {} #for all batch

    for col in filtered_data.columns:
        value_counter = Counter()
        value_counter_all = Counter()

        for source in unique_sources:
            source_data = filtered_data.loc[filtered_data['txtSourceNumber'] == source]

            unique_vals = tuple(sorted(source_data[col].dropna().unique()))
            value_counter[unique_vals] += 1

            unique_vals_all = source_data[col].dropna().tolist()
            value_counter_all.update(unique_vals_all)

        dominance_data[col] = pd.DataFrame(value_counter.items(), columns=["Unique Value Set", "Count"]).sort_values(by="Count", ascending=False)
        all_dominance_data[col] = pd.DataFrame(value_counter_all.items(), columns=["Unique Value", "Count"]).sort_values(by="Count", ascending=False)

    for col in dominance_data.keys():
        print(f"{col}")
        print('=====================================================')
        print('')
        print(f"\nDominant unique value sets in batches: {col}")
        display(dominance_data[col])
        print(f"\nDominant all value sets in batches: {col}")
        display(all_dominance_data[col])
        print('')
        print('=====================================================')

  def summarize_dominance(self, sku):
      filtered_data = dataset.loc[dataset['txtItemDesc'] == sku]
      unique_sources = filtered_data['txtSourceNumber'].unique()

      all_dominance_data = {}

      for col in filtered_data.columns:
          value_counter_all = Counter()

          for source in unique_sources:
              source_data = filtered_data.loc[filtered_data['txtSourceNumber'] == source]
              unique_vals_all = source_data[col].dropna().tolist()
              value_counter_all.update(unique_vals_all)

          all_dominance_data[col] = pd.DataFrame(value_counter_all.items(), columns=["Unique Value", "Count"]).sort_values(by="Count", ascending=False)

      summary = []
      for col, df in all_dominance_data.items():
          if len(df) == 1:
              most_frequent = df.iloc[0]['Unique Value']
              recommendations = 'constant'
              rest_values = 'constant'
          else:
              most_frequent = df.iloc[0]['Unique Value']
              recommendations = df.iloc[1:4]['Unique Value'].tolist()
              if len(df) <= 4:
                rest_values = 'No other Value'
              else:
                rest_values = df.iloc[4:]['Unique Value'].tolist()

          summary.append({
              'Parameter': col,
              'Recommended Value': most_frequent,
              'Other Recommendations': recommendations,
              'Rest of Values': rest_values
          })

      summary_df = pd.DataFrame(summary)
      display(summary_df)

allbatch=all_batch()

"""INPUT JENIS SKU"""

sku ='CHIL GO POWDER 1+ HONEY 950 G (R22-REDUCE NETTO)'

onebatch.print_all(sku)

onebatch.print_unique_in_col(sku)

relative, constant=onebatch.print_value_unique(sku)

print('There are multiple columns which have different parameter:')
print(relative)
print()
print('There are multiple columns which have constant parameter:')
print(constant)

print(f'{sku} UNIQUE SUMMARY:')
onebatch.print_unique_summary(sku)

print('Print all batch summary:')
allbatch.print_all_batch(sku)

print('Columns Values')
relative,constant=allbatch.unique_all_batch(sku)

allbatch.print_count_value_all_batches(sku)

print('PARAMETER RECOMMENDATION')
allbatch.summarize_dominance(sku)

